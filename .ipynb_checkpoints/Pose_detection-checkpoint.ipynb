{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "91f17305",
   "metadata": {
    "code_folding": [
     0
    ],
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (from mediapipe) (1.20.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (from mediapipe) (4.5.5.64)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.1)\n",
      "Requirement already satisfied: six in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (from absl-py->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\danil almahalli\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "# Install mediapipe\n",
    "\n",
    "!pip install mediapipe opencv-python\n",
    "\n",
    "# Display Plot\n",
    "%matplotlib qt\n",
    "\n",
    "# Display console \n",
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "340b41e3",
   "metadata": {
    "code_folding": [],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#Import Properties \n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "# global variable\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "keypoints = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "da13c628",
   "metadata": {
    "code_folding": [
     2
    ],
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read video and extract the coordinate\n",
    "\n",
    "def readvideo (filename,landmarkname):\n",
    "    \n",
    "    #read the video\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    \n",
    "    #count frames\n",
    "    counter=0\n",
    "    \n",
    "    # extract landmark coordinate with list variable\n",
    "    landmark=[]\n",
    "    \n",
    "    # extract important landmark to define initialposition\n",
    "    global keypoints\n",
    "    fillin=[]\n",
    "    \n",
    "    # Check if keypoints are already filled in and it will be reset\n",
    "    if keypoints or None:\n",
    "        keypoints=[]\n",
    "    \n",
    "    # Setup mediapipe instance\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        \n",
    "         while cap.isOpened():\n",
    "              \n",
    "                ret, frame = cap.read()\n",
    "                \n",
    "                # if frame is read correctly ret is True\n",
    "                if not ret:\n",
    "                    print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "                    break\n",
    "                    \n",
    "\n",
    "                counter=counter+1\n",
    "                \n",
    "                # Recolor image to RGB\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "        \n",
    "                # Declare image shape \n",
    "                image_height, image_width, _ = image.shape  \n",
    "                \n",
    "                # Make detection\n",
    "                results = pose.process(image)\n",
    "\n",
    "                #extract landmark\n",
    "                landmarkname_dict={\n",
    "                    \"R_S\":\"RIGHT_SHOULDER\",\n",
    "                    \"L_S\":\"LEFT_SHOULDER\",\n",
    "                    \"R_H\":\"RIGHT_HIP\",\n",
    "                    \"L_H\":\"LEFT_HIP\",\n",
    "                    \"R_K\":\"RIGHT_KNEE\",\n",
    "                    \"L_K\":\"LEFT_KNEE\",\n",
    "                    \"R_A\":\"RIGHT_ANKLE\",\n",
    "                    \"L_A\":\"LEFT_ANKLE\"\n",
    "\n",
    "                }\n",
    "\n",
    "                varlist=[getattr(mp_pose.PoseLandmark,landmarkname_dict[\"R_S\"]),\n",
    "                         getattr(mp_pose.PoseLandmark,landmarkname_dict[\"L_S\"]),\n",
    "                         getattr(mp_pose.PoseLandmark,landmarkname_dict[\"R_H\"]),\n",
    "                         getattr(mp_pose.PoseLandmark,landmarkname_dict[\"L_H\"]),\n",
    "                         getattr(mp_pose.PoseLandmark,landmarkname_dict[\"R_K\"]),\n",
    "                         getattr(mp_pose.PoseLandmark,landmarkname_dict[\"L_K\"]),\n",
    "                         getattr(mp_pose.PoseLandmark,landmarkname_dict[\"R_A\"]),\n",
    "                         getattr(mp_pose.PoseLandmark,landmarkname_dict[\"L_A\"])\n",
    "                         ]\n",
    "  \n",
    "                for i in varlist:\n",
    "                    fillin.append([results.pose_landmarks.landmark[i].x*image_width,\n",
    "                                 results.pose_landmarks.landmark[i].y*image_height])\n",
    "                \n",
    "                keypoints.append(fillin)\n",
    "                fillin=[]\n",
    "                                \n",
    "                # extract landmark\n",
    "                landmark.append([results.pose_landmarks.landmark[getattr(mp_pose.PoseLandmark,landmarkname)].x*image_width,\n",
    "                                                 results.pose_landmarks.landmark[getattr(mp_pose.PoseLandmark,landmarkname)].y*image_height])\n",
    "\n",
    "\n",
    "                # Recolor back to BGR\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "                # Render detections\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                    )               \n",
    "\n",
    "                cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "                if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                    \n",
    "\n",
    "\n",
    "    keypoints = np.array(keypoints)\n",
    "    keypoints = np.transpose(keypoints)\n",
    "    keypoints = list(keypoints)\n",
    "    \n",
    "    # count the number of frames'\n",
    "    frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    frames=int(frames)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(\"FPS= \",fps)\n",
    "\n",
    "    # calculate dusration of the video\n",
    "    seconds = frames/fps\n",
    "    video_time = str(datetime.timedelta(seconds=seconds))\n",
    "    print(\"video time:\", video_time)\n",
    "    \n",
    "    #landmark array transposed\n",
    "    landmark=np.array(landmark)\n",
    "    landmark=np.transpose(landmark)\n",
    "    \n",
    "    #Count size of Image\n",
    "    print(\"HÃ¶he der Image: \",image_height)\n",
    "    print(\"Breite der Image: \",image_width)\n",
    "       \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return landmark,fps,seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "270d8ab2",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Rearrange matrix keypoints\n",
    "\n",
    "def rearrange_matrix():\n",
    "    global keypoints  \n",
    "    \"\"\"\n",
    "      # X-axis\n",
    "        \"RIGHT_SHOULDER.X\":keypoints[0][0],\n",
    "        \"LEFT_SHOULDER.X\":keypoints[0][1],\n",
    "        \"RIGHT_HIP.X\":keypoints[0][2],\n",
    "        \"LEFT_HIP.X\":keypoints[0][3],\n",
    "        \"RIGHT_KNEE.X\":keypoints[0][4],\n",
    "        \"LEFT_KNEE.X\":keypoints[0][5],\n",
    "        \"RIGHT_ANKLE.X\":keypoints[0][6],\n",
    "        \"LEFT_ANKLE.X\":keypoints[0][7],\n",
    "        \n",
    "        # Y-Axis\n",
    "        \n",
    "        \"RIGHT_SHOULDER.Y\":keypoints[1][0],\n",
    "        \"LEFT_SHOULDER.Y\":keypoints[1][1],\n",
    "        \"RIGHT_HIP.Y\":keypoints[1][2],\n",
    "        \"LEFT_HIP.Y\":keypoints[1][3],\n",
    "        \"RIGHT_KNEE.Y\":keypoints[1][4],\n",
    "        \"LEFT_KNEE.Y\":keypoints[1][5],\n",
    "        \"RIGHT_ANKLE.Y\":keypoints[1][6],\n",
    "        \"LEFT_ANKLE.Y\":keypoints[1][7],\n",
    "    \"\"\"\n",
    "    ergebnis_matrix = [[keypoints[0][0],keypoints[1][0]], #RIGHT_SHOULDER\n",
    "                       [keypoints[0][1],keypoints[1][1]], #LEFT_SHOULDER\n",
    "                       [keypoints[0][2],keypoints[1][2]], #RIGHT_HIP\n",
    "                       [keypoints[0][3],keypoints[1][3]], #LEFT_HIP\n",
    "                       [keypoints[0][4],keypoints[1][4]], #RIGHT_KNEE\n",
    "                       [keypoints[0][5],keypoints[1][5]], #LEFT_KNEE\n",
    "                       [keypoints[0][6],keypoints[1][6]], #RIGHT_ANKLE\n",
    "                       [keypoints[0][7],keypoints[1][7]]  #LEFT_ANKLE\n",
    "                      ]\n",
    "    keypoints = ergebnis_matrix\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "0f74359c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Calculate angle between three points\n",
    "\n",
    "def calculateAngle(landmark1,landmark2,landmark3):\n",
    "    \n",
    "    # Get the required landmarks coordinates\n",
    "    x1,y1 = landmark1\n",
    "    x2,y2 = landmark2\n",
    "    x3,y3 = landmark3\n",
    "    \n",
    "    sample = int(fps_standard*zeit_standard)\n",
    "    # Calculate the angle between the three points\n",
    "    ang = []\n",
    "    \n",
    "    for i in range(sample):\n",
    "        ang.append(math.degrees(math.atan2(y3[i]-y2[i], x3[i]-x2[i]) - math.atan2(y1[i]-y2[i],\n",
    "                                                             x1[i]-x2[i])))\n",
    "    \n",
    "    for i in range(sample):\n",
    "        if ang[i] < 0 :\n",
    "            ang[i] = ang[i]+360\n",
    "                                                                    \n",
    "    return ang   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "08909ebf",
   "metadata": {
    "code_folding": [
     18
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate Initial Position\n",
    "\n",
    "def calc_init_position():\n",
    "    \n",
    "    \"\"\" Hier wird erstmal die Liste von Coordinates aufgelistet, um\n",
    "    die Code lesbar zu machen. Dazu wird erstmal mit der AbkÃ¼rzung\n",
    "    die Elemente von Coordinates definieren\n",
    "    \"\"\"\n",
    "    global keypoints\n",
    "    \n",
    "    sample = int(fps_standard*zeit_standard)\n",
    "    left_knee_winkel = []\n",
    "    right_knee_winkel=[]\n",
    "    hip_winkel = []\n",
    "    \n",
    "    middle_hip = []\n",
    "    middle_knee = []\n",
    "    middle_ankle = []\n",
    "    \n",
    "    for i in range(sample):\n",
    "        middle_hip.append([min(keypoints[2][0][i],keypoints[3][0][i])+\n",
    "                           np.abs(keypoints[2][0][i]-keypoints[3][0][i])/2,\n",
    "                           min(keypoints[2][1][i],keypoints[3][1][i])+\n",
    "                           np.abs(keypoints[2][1][i]-keypoints[3][1][i])/2]\n",
    "                          )\n",
    "        middle_knee.append([min(keypoints[4][0][i],keypoints[5][0][i])+\n",
    "                           np.abs(keypoints[4][0][i]-keypoints[5][0][i])/2,\n",
    "                           min(keypoints[4][1][i],keypoints[5][1][i])+\n",
    "                           np.abs(keypoints[4][1][i]-keypoints[5][1][i])/2]\n",
    "                          )\n",
    "        middle_ankle.append([min(keypoints[6][0][i],keypoints[7][0][i])+\n",
    "                           np.abs(keypoints[6][0][i]-keypoints[7][0][i])/2,\n",
    "                           min(keypoints[6][1][i],keypoints[7][1][i])+\n",
    "                           np.abs(keypoints[6][1][i]-keypoints[7][1][i])/2]\n",
    "                          )\n",
    "    \n",
    "    middle_hip=np.transpose(middle_hip)\n",
    "    middle_knee=np.transpose(middle_knee)\n",
    "    middle_ankle=np.transpose(middle_ankle)\n",
    "    \n",
    "    \n",
    "    left_knee_winkel = calculateAngle(keypoints[3],keypoints[5],keypoints[7])\n",
    "    right_knee_winkel = calculateAngle(keypoints[2],keypoints[4],keypoints[6])\n",
    "    hip_winkel = calculateAngle(middle_hip,middle_knee,middle_ankle)\n",
    "    \n",
    "    left_knee_winkel = list(map(int,left_knee_winkel))\n",
    "    right_knee_winkel = list(map(int,right_knee_winkel))\n",
    "    hip_winkel = list(map(int,hip_winkel))\n",
    "    \n",
    "    \n",
    "    sample_periode = 1/fps_standard\n",
    "    \n",
    "    w_tol = range(178,182)\n",
    "    \n",
    "    zeitpunkt=[]\n",
    "    \n",
    "    for i in range(sample):\n",
    "        if left_knee_winkel[i] in w_tol and right_knee_winkel[i] in w_tol:\n",
    "            zeitpunkt.append((i+1)*sample_periode)\n",
    "            \n",
    "    return right_knee_winkel\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "44392ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeitpunkt=calc_init_position()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bd85e",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Cost Matrix\n",
    "\n",
    "def dp(dist_mat):\n",
    "    \"\"\"\n",
    "    Find minimum-cost path through matrix `dist_mat` using dynamic programming.\n",
    "\n",
    "    The cost of a path is defined as the sum of the matrix entries on that\n",
    "    path. See the following for details of the algorithm:\n",
    "\n",
    "    - http://en.wikipedia.org/wiki/Dynamic_time_warping\n",
    "    - https://www.ee.columbia.edu/~dpwe/resources/matlab/dtw/dp.m\n",
    "\n",
    "    The notation in the first reference was followed, while Dan Ellis's code\n",
    "    (second reference) was used to check for correctness. Returns a list of\n",
    "    path indices and the cost matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    N, M = dist_mat.shape\n",
    "    \n",
    "    # Initialize the cost matrix\n",
    "    # \n",
    "    cost_mat = np.zeros((N + 1, M + 1))\n",
    "    for i in range(1, N + 1):\n",
    "        cost_mat[i, 0] = np.inf\n",
    "    for i in range(1, M + 1):\n",
    "        cost_mat[0, i] = np.inf\n",
    "\n",
    "    # Fill the cost matrix while keeping traceback information\n",
    "    traceback_mat = np.zeros((N, M))\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            penalty = [\n",
    "                cost_mat[i, j],      # match (0)\n",
    "                cost_mat[i, j + 1],  # insertion (1)\n",
    "                cost_mat[i + 1, j]]  # deletion (2)\n",
    "            i_penalty = np.argmin(penalty)\n",
    "            cost_mat[i + 1, j + 1] = dist_mat[i, j] + penalty[i_penalty]\n",
    "            traceback_mat[i, j] = i_penalty\n",
    "\n",
    "    # Traceback from bottom right\n",
    "    i = N - 1\n",
    "    j = M - 1\n",
    "    path = [(i, j)]\n",
    "    while i > 0 or j > 0:\n",
    "        tb_type = traceback_mat[i, j]\n",
    "        if tb_type == 0:\n",
    "            # Match\n",
    "            i = i - 1\n",
    "            j = j - 1\n",
    "        elif tb_type == 1:\n",
    "            # Insertion\n",
    "            i = i - 1\n",
    "        elif tb_type == 2:\n",
    "            # Deletion\n",
    "            j = j - 1\n",
    "        path.append((i, j))\n",
    "\n",
    "    # Strip infinity edges from cost_mat before returning\n",
    "    cost_mat = cost_mat[1:, 1:]\n",
    "    return (path[::-1],cost_mat,N,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a43e4",
   "metadata": {
    "code_folding": [
     2
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plotting coordinate Landmark\n",
    "\n",
    "def plottingcoordinate (signal1,signal2):\n",
    "    \n",
    "    \n",
    "    xlist=np.linspace(0,zeit_standard,len(signal1[0]))\n",
    "    xlist2=np.linspace(0,zeit_sample,len(signal2[0]))\n",
    "    \n",
    "    y_landmarks1=signal1\n",
    "    y_landmarks2=signal2\n",
    "    \n",
    "    #plot x,y,z axis from  landmarks\n",
    "    \n",
    "    fig, axs = plt.subplots(2)\n",
    "    subtitle=[\"Landmark in x-axis\",\"Landmark  in y-axis\"]\n",
    "    for i in range(2):\n",
    "        axs[i].set_title(subtitle[i])\n",
    "        axs[i].plot(xlist,y_landmarks1[i],label=\"Standard\")\n",
    "        axs[i].plot(xlist2,y_landmarks2[i],label=\"Sample\")\n",
    "        axs[i].set(xlabel=\"time in s\",ylabel=\"position in cm\")\n",
    "        axs[i].legend(loc='upper left')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0d6394",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Distance matrix\n",
    "\n",
    "def distance_matrix(signal1,signal2):\n",
    "        N = signal1.shape[0]\n",
    "        M = signal2.shape[0]\n",
    "        dist_mat = np.zeros((N, M))\n",
    "        for i in range(N):\n",
    "            for j in range(M):\n",
    "                dist_mat[i, j] = abs(signal1[i] - signal2[j])\n",
    "        return dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37290738",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# DTW Plotting\n",
    "def dtw_plotting(i,signal1,signal2):\n",
    "    dist_mat=distance_matrix(signal1[i],signal2[i])\n",
    "    path, cost_mat,N,M = dp(dist_mat)\n",
    "   \n",
    "\n",
    "    print(\"Alignment cost: {:.4f}\".format(cost_mat[N - 1, M - 1]))\n",
    "    print(\"Normalized alignment cost: {:.4f}\".format(cost_mat[N - 1, M - 1]/(N + M)))\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.subplot(121)\n",
    "    plt.title(\"Distance matrix\")\n",
    "    plt.xlabel(\"Signal_sample\")\n",
    "    plt.ylabel(\"Signal_standard\")\n",
    "    plt.imshow(dist_mat, cmap=plt.cm.binary, interpolation=\"nearest\", origin=\"lower\")\n",
    "    plt.subplot(122)\n",
    "    plt.title(\"Cost matrix\")\n",
    "    plt.xlabel(\"Signal_sample\")\n",
    "    plt.ylabel(\"Signal_standard\")\n",
    "    plt.imshow(cost_mat, cmap=plt.cm.binary, interpolation=\"nearest\", origin=\"lower\")\n",
    "    x_path, y_path = zip(*path)\n",
    "    plt.plot(y_path, x_path); # i for Coordinate, x_axis=0, y_axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33668152",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Mittelwertoptimierung\n",
    "\n",
    "def mittelwertopt(signal1,signal2):\n",
    "\n",
    "    for i in range(2):\n",
    "        signal1[i]=signal1[i]-np.mean(signal1[i])\n",
    "        signal2[i]=signal2[i]-np.mean(signal2[i])\n",
    "        \n",
    "    return signal1,signal2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ec4e1",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Frequency analysis\n",
    "\n",
    "def fft_analysis(signal1,signal2,i,fps1,fps2):\n",
    "    \n",
    "    samplingFrequency = [int(fps1),int(fps2)]\n",
    "    samplingInterval = []\n",
    "    for i in range(len(samplingFrequency)):\n",
    "        samplingInterval.append(1/samplingFrequency[i])\n",
    "    \n",
    "    \n",
    "    fouriersignal1 = np.fft.fft(signal1[i])/len(signal1[i])\n",
    "    fouriersignal2 = np.fft.fft(signal2[i])/len(signal2[i]) \n",
    "    \n",
    "    fouriersignal1 = fouriersignal1[range(int(len(signal1[i])/2))]\n",
    "    fouriersignal2 = fouriersignal2[range(int(len(signal2[i])/2))]\n",
    "    \n",
    "    fouriersignal1 = np.abs(fouriersignal1)\n",
    "    fouriersignal2 = np.abs(fouriersignal2)\n",
    "    \n",
    "    \n",
    "    tpcount=[len(signal1[i]),len(signal2[i])]\n",
    "    values=[]\n",
    "    timeperiod=[]\n",
    "    frequencies=[]\n",
    "    \n",
    "    for i in range (len(tpcount)):\n",
    "        values.append(np.arange(int(tpcount[i]/2)))\n",
    "        timeperiod.append(tpcount[i]/samplingFrequency[i])\n",
    "        frequencies.append(values[i]/timeperiod[i])\n",
    "    \n",
    "    peaks1,_ = find_peaks(fouriersignal1,height = 20)\n",
    "    peaks2,_ = find_peaks(fouriersignal2,height = 20)\n",
    "\n",
    "  \n",
    "    fig,(axs1,axs2)=plt.subplots(2)\n",
    "    fig.suptitle(\"FFT Analysis\")\n",
    "    axs1.plot(frequencies[0],fouriersignal1,'tab:blue')\n",
    "    axs1.plot([frequencies[0][i] for i in peaks1],fouriersignal1[peaks1],\"x\")\n",
    "    axs1.set_ylim(0,50)\n",
    "    axs1.set_xlim(0,10)\n",
    "    axs1.set(xlabel=\"Frequency in Hz\")\n",
    "    axs2.plot(frequencies[1],fouriersignal2,'tab:orange')\n",
    "    axs2.plot([frequencies[1][j] for j in peaks2],fouriersignal2[peaks2],\"x\")\n",
    "    axs2.set(xlabel=\"Frequency in Hz\")\n",
    "    axs2.set_ylim(0,50)\n",
    "    axs2.set_xlim(0,10)\n",
    "    \n",
    "    return str([frequencies[0][i] for i in peaks1]),str([frequencies[1][i] for i in peaks2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d866c5d3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# fft example\n",
    "spFrequency=20\n",
    "spInterval=1/spFrequency\n",
    "time=np.arange(0,10,spInterval)\n",
    "s1=3\n",
    "s2=8\n",
    "amplitude=np.sin(2*np.pi*s1*time)+np.sin(2*np.pi*s2*time)\n",
    "print(\"count amplitude\",len(amplitude))\n",
    "fgr,axs=plt.subplots(2,1)\n",
    "axs[0].plot(time,amplitude)\n",
    "\n",
    "tpCount     = len(amplitude)\n",
    "values      = np.arange(int(tpCount/2))\n",
    "timePeriod  = tpCount/spFrequency\n",
    "frequencies = values/timePeriod\n",
    "fourierTransform = np.fft.fft(amplitude)/len(amplitude)\n",
    "print(type(fourierTransform))\n",
    "print(len(amplitude))\n",
    "fourierTransform = fourierTransform[range(int(len(amplitude)/2))]\n",
    "axs[1].plot(frequencies,np.abs(fourierTransform))\n",
    "axs[1].set_xlim(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dbee12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peaks1,peaks2=fft_analysis(landmark_standard,landmark_sample,0,fps_standard,fps_sample)\n",
    "print(\"Frequency Signal 1 = \",peaks1)\n",
    "print(\"Frequency Signal 2 = \",peaks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "92199e0c",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't receive frame (stream end?). Exiting ...\n",
      "FPS=  23.97602857776778\n",
      "video time: 0:00:14.472789\n",
      "HÃ¶he der Image:  1080\n",
      "Breite der Image:  1920\n",
      "Count frame:  347\n"
     ]
    }
   ],
   "source": [
    "# Read Standard Video\n",
    "landmark_standard,fps_standard,zeit_standard=readvideo(\"squat_standard_ohneFPSrecons.mp4\",\"RIGHT_ANKLE\")\n",
    "print(\"Count frame: \", int(fps_standard*zeit_standard))\n",
    "\n",
    "# Rearrange Element from keypoints\n",
    "rearrange_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a0aa519c",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "RIGH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DANILA~1\\AppData\\Local\\Temp/ipykernel_9704/1014621483.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read Sample Video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlandmark_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfps_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mzeit_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreadvideo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"squat_sample_24FPS.mp4\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"RIGH\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\DANILA~1\\AppData\\Local\\Temp/ipykernel_9704/2761199750.py\u001b[0m in \u001b[0;36mreadvideo\u001b[1;34m(filename, landmarkname)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;31m# extract landmark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                 landmark.append([results.pose_landmarks.landmark[getattr(mp_pose.PoseLandmark,landmarkname)].x*image_width,\n\u001b[0m\u001b[0;32m     79\u001b[0m                                                  results.pose_landmarks.landmark[getattr(mp_pose.PoseLandmark,landmarkname)].y*image_height])\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\enum.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_member_map_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: RIGH"
     ]
    }
   ],
   "source": [
    "# Read Sample Video\n",
    "landmark_sample,fps_sample,zeit_sample=readvideo(\"squat_sample_24FPS.mp4\",\"RIGH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af00f9d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot landmark from both of Videos\n",
    "plottingcoordinate(landmark_standard,landmark_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_standard,landmark_sample=mittelwertopt(landmark_standard,landmark_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1452fbdf",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot Residum\n",
    "dtw_plotting(0,landmark_standard,landmark_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca1c1c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# einfache Beispiel, unterschiedliche  Samplingrate -> Informationsverlust\n",
    "\n",
    "fps1 = 20\n",
    "fps2 = 10\n",
    "x1 = np.arange(0,1,1/fps1)\n",
    "x2 = np.arange(0,1,1/fps2)\n",
    "y1 = [np.sin(2*np.pi*x1)]\n",
    "y2 = [np.sin(2*np.pi*x2)]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.title(\"Two sinus function with different sample frequency\")\n",
    "plt.plot(x1, y1[0])\n",
    "plt.plot(x2, y2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f08cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtw_plotting(0,y1,y2)\n",
    "# Wenn der Frame unterschiedlich ist, sieht mann, dass es Informationsverlust gibt, weil das Video wenige Frame aufnimmt\n",
    "# nimmt es dazwischen kein Coordinate und sowas gibt es Verlust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7729a3e8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# List from Landmarks\n",
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
